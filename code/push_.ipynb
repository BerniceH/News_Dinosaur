{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_now():\n",
    "    Endpoint='http://chatbot_line:5000/pushMessage'\n",
    "    Response=requests.get(Endpoint)\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_two_days_ago_url():\n",
    "    ip_location='chatbot_api'\n",
    "    Endpoint='http://%s:5000/delete_push_news' % (ip_location)\n",
    "    push=requests.get(Endpoint)\n",
    "    push = push.json()\n",
    "    delete_line_url(push['part_a1_url'])\n",
    "    delete_line_url(push['part_a2_url'])\n",
    "    delete_line_url(push['part_a3_url'])\n",
    "    delete_line_url(push['part_b1_url'])\n",
    "    delete_line_url(push['part_b2_url'])\n",
    "    delete_line_url(push['part_b3_url'])\n",
    "    delete_line_url(push['part_c1_url'])\n",
    "    delete_line_url(push['part_c2_url'])\n",
    "    delete_line_url(push['part_c3_url'])\n",
    "    return \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def delete_line_url(my_url):\n",
    "    url = my_url.replace(\"line://app/\", \"\")\n",
    "    line_url = os.popen('''curl -X DELETE https://api.line.me/liff/v1/apps/\"%s\" \\\n",
    "    -H \"Authorization: Bearer PpbRXLtugi6fiaO+7JGQ/BGH5mJI8cPowNWJlR3nWIoHkZy4oAOlKnvpgMefhetNMdW4i1ZVWtjo+8VO1CqK+3P5hRt61g4YJGPSnMHQQr4nSPqBDlWI5RhaBvXCATNyodPIc1Hi9OzccgbgrVQgxgdB04t89/1O/w1cDnyilFU=\"''' % (url)) \n",
    "\n",
    "    line_url.close\n",
    "    return \"OK\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def get_push_news():\n",
    "    if_end = True\n",
    "    store_datetime = datetime.datetime.now().strftime(\"%Y/%m/%d\")\n",
    "\n",
    "    Endpoint='http://chatbot_api:5000/today_news'\n",
    "\n",
    "    todaynews = requests.get(Endpoint)\n",
    "    data = todaynews.json()\n",
    "\n",
    "    my_json = []\n",
    "    for page in range(1, 12):\n",
    "        if if_end == False:\n",
    "            break\n",
    "        href = \"https://tw.news.appledaily.com/politics/realtime/\"+ str(page)\n",
    "        res = requests.get(href)\n",
    "        html = BeautifulSoup(res.text)\n",
    "        all_news_1 = html.find_all(\"ul\", class_=\"rtddd slvl\")\n",
    "        for all_news in all_news_1:\n",
    "            if if_end == False:\n",
    "                break\n",
    "            news = all_news.find_all(\"a\")\n",
    "            for n in news:\n",
    "                my_news = {}\n",
    "                news_url =\"https://tw.news.appledaily.com/\" + str(n[\"href\"])\n",
    "                news_per = requests.get(news_url)\n",
    "                bs = BeautifulSoup(news_per.text)\n",
    "\n",
    "                if bs.find(\"div\", class_=\"ndArticle_view\") == None:\n",
    "                    views = 0\n",
    "                else:\n",
    "                    views = int(bs.find(\"div\", class_=\"ndArticle_view\").text)\n",
    "                date_time = bs.find(\"div\", class_=\"ndArticle_creat\").text.replace(\"出版時間：\", \"\").split(\" \")[0]\n",
    "                if not date_time == store_datetime:\n",
    "                    if_end = False\n",
    "                    break\n",
    "                my_news= {\"url\": news_url, \"views\": views}\n",
    "                my_json.append(my_news)\n",
    "\n",
    "    sorted_json = sorted(my_json ,key = lambda my_json:my_json['views'], reverse = True)\n",
    "    all_push_news= news_push(data, url_change_titleid(sorted_json[0]['url']), url_change_titleid(sorted_json[1]['url']), url_change_titleid(sorted_json[2]['url']), url_change_titleid(sorted_json[3]['url']))\n",
    "\n",
    "    push_news = []\n",
    "    for a in all_push_news:\n",
    "        if len(push_news) < 3:\n",
    "            if len(a) == 3:\n",
    "                push_news.append(a)\n",
    "    my_push = []\n",
    "    for push_new in push_news:\n",
    "        if not title_id_get_img(push_new[0]) == '':\n",
    "            my_push.append(push_new)\n",
    "        elif not title_id_get_img(push_new[1]) == '':\n",
    "            news = [push_new[1], push_new[0], push_new[2]]\n",
    "            my_push.append(news)\n",
    "        elif not title_id_get_img(push_new[2]) == '':\n",
    "            news = [push_new[2], push_new[0], push_new[1]]\n",
    "\n",
    "    ip_location='chatbot_api'\n",
    "\n",
    "    push = {} \n",
    "    push['part_a1'] = str(my_push[0][0])\n",
    "    push['part_a1_url'] = get_line_url(my_push[0][0])\n",
    "    push['part_a2']= str(my_push[0][1])\n",
    "    push['part_a2_url']= get_line_url(my_push[0][1])\n",
    "    push['part_a3'] = str(my_push[0][2])\n",
    "    push['part_a3_url'] = get_line_url(my_push[0][2])\n",
    "    push['part_b1'] = str(my_push[1][0])\n",
    "    push['part_b1_url']= get_line_url(my_push[1][0])\n",
    "    push['part_b2']= str(my_push[1][1])\n",
    "    push['part_b2_url']= get_line_url(my_push[1][1])\n",
    "    push['part_b3'] = str(my_push[1][2])\n",
    "    push['part_b3_url'] = get_line_url(my_push[1][2])\n",
    "    push['part_c1'] = str(my_push[2][0])\n",
    "    push['part_c1_url'] = get_line_url(my_push[2][0])\n",
    "    push['part_c2'] = str(my_push[2][1])\n",
    "    push['part_c2_url'] = get_line_url(my_push[2][1])\n",
    "    push['part_c3'] = str(my_push[2][2])\n",
    "    push['part_c3_url'] =  get_line_url(my_push[2][2])\n",
    "\n",
    "\n",
    "    # 將json傳回API Server\n",
    "    Endpoint='http://%s:5000/push_news' % (ip_location)\n",
    "\n",
    "\n",
    "    # header要特別註明是json格式\n",
    "    Header={'Content-Type':'application/json'}\n",
    "\n",
    "    # 傳送post對API server新增資料 \n",
    "    Response=requests.post(Endpoint,headers=Header,data=json.dumps(push))\n",
    "\n",
    "    #印出Response的資料訊息\n",
    "    Response = Response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_line_url(title_id):\n",
    "    url = \"https://871e9e6c.ngrok.io/newspaper/\"+ str(title_id)\n",
    "    line_url = os.popen(\"\"\"curl -XPOST \\\n",
    "    -H \"Authorization: Bearer PpbRXLtugi6fiaO+7JGQ/BGH5mJI8cPowNWJlR3nWIoHkZy4oAOlKnvpgMefhetNMdW4i1ZVWtjo+8VO1CqK+3P5hRt61g4YJGPSnMHQQr4nSPqBDlWI5RhaBvXCATNyodPIc1Hi9OzccgbgrVQgxgdB04t89/1O/w1cDnyilFU=\" \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d '{\n",
    "        \"view\": {\n",
    "            \"type\": \"tall\",\n",
    "            \"url\": \" '%s' \"\n",
    "        }\n",
    "    }' \\\n",
    "    https://api.line.me/liff/v1/apps\"\"\" % (url)) \n",
    "\n",
    "    my_link = \"line://app/\"+json.loads(line_url.read())['liffId']\n",
    "    line_url.close\n",
    "    return my_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gensim\n",
    "import glob\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import jieba\n",
    "\n",
    "def news_push(data, most_views_news1, most_views_news2, most_views_news3, most_views_news4):\n",
    "    df_all = pd.DataFrame(columns=[\"title_id\", \"origin_id\", \"title\", \"url\", \"content\"])\n",
    "    df = pd.DataFrame.from_dict(data, orient=\"columns\")\n",
    "    df_all = pd.concat([df_all, df], axis=0, ignore_index=True)\n",
    "\n",
    "    df = df_all\n",
    "    df = df.drop([\"url\"], axis=1)\n",
    "    df = df.drop([\"origin_id\"], axis=1)\n",
    "    df = df.drop([\"title\"], axis=1)\n",
    "\n",
    "    def split_news(news):\n",
    "        return \" \".join(jieba.cut(news))\n",
    "\n",
    "    def process_news(df):\n",
    "        df['content'] = df ['content'].apply(split_news)\n",
    "        return df\n",
    "    df = process_news(df)\n",
    "\n",
    "\n",
    "    TaggededDocument = gensim.models.doc2vec.TaggedDocument\n",
    "\n",
    "    news_list = []\n",
    "    for i in range(0, len(df)):\n",
    "        news = list(df.iloc[i])\n",
    "        news_list.append(news)\n",
    "\n",
    "    x_train=[]\n",
    "    for content, title_id in news_list:\n",
    "        word_list = content.split(' ')\n",
    "        l = len(word_list)\n",
    "        word_list[l-1]=word_list[l-1].strip()\n",
    "        document=TaggededDocument(word_list,tags=[title_id])\n",
    "        x_train.append(document)\n",
    "    c = x_train\n",
    "\n",
    "\n",
    "    model = Doc2Vec(x_train, min_count=1, window=3, vector_size=100, negative=5,workers=4)\n",
    "    model.train(x_train,total_examples=model.corpus_count,epochs=10)\n",
    "    model_dm = model\n",
    "\n",
    "    most_views = [most_views_news1, most_views_news2, most_views_news3]\n",
    "    exist_title_id_list = []\n",
    "\n",
    "    # 第一個推播\n",
    "    strl = df[\"title_id\"] == most_views_news1\n",
    "    news_index = int(str(df[strl][\"content\"]).split(\" \")[0])\n",
    "    test_text = df[strl][\"content\"][news_index].split(' ')\n",
    "    #得到向量array命名為inferred_vector\n",
    "    inferred_vector = model_dm.infer_vector(doc_words = test_text, alpha=0.025, steps=500)\n",
    "\n",
    "    sims = model_dm.docvecs.most_similar([inferred_vector],topn=12)\n",
    "\n",
    "    title_id_list1 = []\n",
    "    for title_id, sim in sims:\n",
    "        title_id_list1.append(title_id)\n",
    "        exist_title_id_list.append(title_id)\n",
    "\n",
    "    # 第二個推播\n",
    "    strl = df[\"title_id\"] == most_views_news2\n",
    "    news_index = int(str(df[strl][\"content\"]).split(\" \")[0])\n",
    "    test_text = df[strl][\"content\"][news_index].split(' ')\n",
    "    #得到向量array命名為inferred_vector\n",
    "    inferred_vector = model_dm.infer_vector(doc_words = test_text, alpha=0.025, steps=500)\n",
    "\n",
    "    sims = model_dm.docvecs.most_similar([inferred_vector],topn=12)\n",
    "\n",
    "    title_id_list2 = []\n",
    "    for title_id, sim in sims:\n",
    "        if title_id not in exist_title_id_list:\n",
    "            title_id_list2.append(title_id)\n",
    "            exist_title_id_list.append(title_id)\n",
    "\n",
    "    # 第三個推播\n",
    "    strl = df[\"title_id\"] == most_views_news3\n",
    "    news_index = int(str(df[strl][\"content\"]).split(\" \")[0])\n",
    "    test_text = df[strl][\"content\"][news_index].split(' ')\n",
    "    #得到向量array命名為inferred_vector\n",
    "    inferred_vector = model_dm.infer_vector(doc_words = test_text, alpha=0.025, steps=500)\n",
    "\n",
    "    sims = model_dm.docvecs.most_similar([inferred_vector],topn=12)\n",
    "\n",
    "    title_id_list3 = []\n",
    "    for title_id, sim in sims:\n",
    "        if title_id not in exist_title_id_list:\n",
    "            title_id_list3.append(title_id)\n",
    "            exist_title_id_list.append(title_id)\n",
    "\n",
    "    # 第四個推播\n",
    "    strl = df[\"title_id\"] == most_views_news4\n",
    "    news_index = int(str(df[strl][\"content\"]).split(\" \")[0])\n",
    "    test_text = df[strl][\"content\"][news_index].split(' ')\n",
    "    # 得到向量array命名為inferred_vector\n",
    "    inferred_vector = model_dm.infer_vector(doc_words=test_text, alpha=0.025, steps=500)\n",
    "\n",
    "    sims = model_dm.docvecs.most_similar([inferred_vector], topn=12)\n",
    "\n",
    "    title_id_list4 = []\n",
    "    for title_id, sim in sims:\n",
    "        if title_id not in exist_title_id_list:\n",
    "            title_id_list4.append(title_id)\n",
    "            exist_title_id_list.append(title_id)\n",
    "\n",
    "    return(title_id_list1[:3], title_id_list2[:3], title_id_list3[:3], title_id_list4[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "def title_id_get_img(title_id):\n",
    "    ip_location='chatbot_api'\n",
    "    playload = {\"title_id\": title_id}\n",
    "    Endpoint='http://%s:5000/push_needed/%s'% (ip_location, playload[\"title_id\"])\n",
    "\n",
    "    a1=requests.get(Endpoint)\n",
    "    return a1.json()['img_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def url_change_titleid(url):\n",
    "    ip_location='chatbot_api'\n",
    "    playload = {\"url\" : url}\n",
    "    Endpoint='http://%s:5000/get_title_id/' % (ip_location)\n",
    "\n",
    "    # header要特別註明是json格式\n",
    "    Header={'Content-Type':'application/json'}\n",
    "\n",
    "    # 傳送post對API server新增資料 \n",
    "    Response=requests.post(Endpoint,headers=Header,data=json.dumps(playload))\n",
    "\n",
    "    #印出Response的資料訊息\n",
    "\n",
    "    return Response.json()['title_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def url_change_titleid(url):\n",
    "    ip_location='chatbot_api'\n",
    "    playload = {\"url\" : url}\n",
    "    Endpoint='http://%s:5000/get_title_id/' % (ip_location)\n",
    "\n",
    "    # header要特別註明是json格式\n",
    "    Header={'Content-Type':'application/json'}\n",
    "\n",
    "    # 傳送post對API server新增資料 \n",
    "    Response=requests.post(Endpoint,headers=Header,data=json.dumps(playload))\n",
    "\n",
    "    #印出Response的資料訊息\n",
    "\n",
    "    return Response.json()['title_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.649 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/opt/conda/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8b2040bf66ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!pip install schedule\n",
    "import schedule\n",
    "import time\n",
    "import datetime\n",
    "import threading\n",
    "\n",
    "schedule.every().day.at(\"11:45\").do(get_push_news)\n",
    "schedule.every().day.at(\"12:00\").do(push_now)\n",
    "#schedule.every().day.at(\"10:37\").do(delete_two_days_ago_url)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
